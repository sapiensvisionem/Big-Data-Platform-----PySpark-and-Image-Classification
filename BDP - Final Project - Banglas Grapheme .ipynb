{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import TimestampType\n",
    "from pyspark.sql.functions import unix_timestamp\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.models import clone_model\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization, Input\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import Dense, Lambda\n",
    "from keras.models  import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D,Input\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "import efficientnet.keras as efn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms,models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('ReadData').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = spark.sparkContext._conf.setAll([('spark.executor.memory', '4g'), ('spark.app.name', 'Spark Updated Conf'), ('spark.executor.cores', '4'), ('spark.cores.max', '4'), ('spark.driver.memory','4g')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data_purchase.csv file\n",
    "train_df_ = spark.read.csv((\"train.csv\", inferSchema=True, header=True)\n",
    "test_df_ = spark.read.csv('test.csv', inferSchema=True, header=True)\n",
    "class_map_df = spark.read.csv('class_map.csv', inferSchema=True, header=True)\n",
    "sample_sub_df = spark.read.csv(('sample_submission.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# purely for heuristic exercise to show date manipulation can be done\n",
    "# date column was not actually used for training\n",
    "df1 = train_df.withColumn('train_dt', unix_timestamp('tran_dt', 'yyyy-MM-dd').cast('timestamp'))\n",
    "df1 = df1.filter(\"train_dt like 'PST%' or tain_dt like 'CST%' or train_dt like 'EST%' or train_dt like 'MST%'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRIMARY DATA WRANGLING OPERATION HERE\n",
    "# join with another table, group by some column, summarize (count), arrange rows by some column, and displaying the first 10 rows (^=\n",
    "counts = train_df.groupby('grapheme_root').count()\n",
    "train_df.join(counts, 'grapheme_root').select('grapheme_root','grapheme','count').orderBy(['count'], ascending=[0]).show(10)\n",
    "# can also do by filter(.count > 1000) - choose some threshold level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to join back with the original table\n",
    "df2 = train_df.join(counts, 'grapheme_root').select('grapheme_root','grapheme','count').orderBy(['count'], ascending=[0])\n",
    "# Bar chart - Top 10 events based on total purchased tickets amount\n",
    "df2.plot(kind= 'bar', x='grapheme_counts', y='count', figsize=(20,7), grid=True, rot=30, ylim=(4000, 75000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data - remove whitespace from any text data\n",
    "charReplace = udf(lambda x: x.replace(u' ',''))\n",
    "df1 = df.withColumn('grapheme_root',charReplace('grapheme_root'))\n",
    "df1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "df2 = df1.drop('id')\n",
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the duplicate rows based on class_maping\n",
    "class_map_df = class_map_df.drop_duplicates(subset=['grapheme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram in probabilsitic distribution\n",
    "fig = px.histogram(train_df, x=\"grapheme_root\", histnorm='probability', title=\"Grapheme Occurance Count in order of Grapheme Root\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vowel diacritic occurrence count\n",
    "fig = px.histogram(train_df, x=\"vowel_diacritic\", title=\"Vowel Diacritic Occurance Count\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vowel diacritic count\n",
    "dfb = train_df.groupby(\"vowel_diacritic\").count()\n",
    "fig = px.bar(dfb[\"grapheme\"].sort_values(), y=\"grapheme\", title=\"Vowel Diacritic Occurance Count Sorted from Low to High\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consonant diacritic count\n",
    "fig = px.histogram(train_df, x=\"consonant_diacritic\", title=\"Vowel Diacritic Occurance Count\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grapheme Count: \n",
    "dfb = df.groupby(\"consonant_diacritic\").count()\n",
    "fig = px.bar(dfb[\"grapheme\"].sort_values(), y=\"grapheme\", title=\"Consonant Diacritic Occurance Count Sorted from Low to High\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Using Pandas ^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to show the actual images we use pd.read_parquet function\n",
    "def load_as_npa(file):\n",
    "    df = pd.read_parquet(file)\n",
    "    return df.iloc[:, 0], df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH)\n",
    "\n",
    "def image_from_char(char):\n",
    "    image = Image.new('RGB', (WIDTH, HEIGHT))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    myfont = ImageFont.truetype('/kaggle/input/bengaliai/hind_siliguri_normal_500.ttf', 120)\n",
    "    w, h = draw.textsize(char, font=myfont)\n",
    "    draw.text(((WIDTH - w) / 2,(HEIGHT - h) / 2), char, font=myfont)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids0, images0 = load_as_npa('train_image_data_0.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(5, 5, figsize=(16, 8))\n",
    "ax = ax.flatten()\n",
    "\n",
    "for i in range(25):\n",
    "    ax[i].imshow(images0[i], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique grapheme_root: {}\".format(train_df['grapheme_root'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Histogram(x=train_df['grapheme_root'])])\n",
    "fig.update_layout(title_text='`grapheme_root` values')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most common grapheme_root values\n",
    "x = train_df['grapheme_root'].value_counts().sort_values()[-20:].index\n",
    "y = train_df['grapheme_root'].value_counts().sort_values()[-20:].values\n",
    "fig = go.Figure(data=[go.Bar(x=x, y=y)])\n",
    "fig.update_layout(title_text='Most common grapheme_root values')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least common grapheme_root values\n",
    "x = train_df['grapheme_root'].value_counts().sort_values()[:20].index\n",
    "y = train_df['grapheme_root'].value_counts().sort_values()[:20].values\n",
    "fig = go.Figure(data=[go.Bar(x=x, y=y)])\n",
    "fig.update_layout(title_text='Least common grapheme_root values')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vowel_diacritic values\n",
    "x = train_df['vowel_diacritic'].value_counts().sort_values().index\n",
    "y = train_df['vowel_diacritic'].value_counts().sort_values().values\n",
    "fig = go.Figure(data=[go.Bar(x=x, y=y)])\n",
    "fig.update_layout(title_text='vowel_diacritic values')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consonant_diacritic values\n",
    "x = train_df['consonant_diacritic'].value_counts().sort_values().index\n",
    "y = train_df['consonant_diacritic'].value_counts().sort_values().values\n",
    "fig = go.Figure(data=[go.Bar(x=x, y=y)])\n",
    "fig.update_layout(title_text='consonant_diacritic values')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function outputs the top/bottom n rows in a nice format with data types\n",
    "def get_n(df, field, n, top=True):\n",
    "    top_graphemes = df.groupby([field]).size().reset_index(name='counts')['counts'].sort_values(ascending=not top)[:n]\n",
    "    top_grapheme_roots = top_graphemes.index\n",
    "    top_grapheme_counts = top_graphemes.values\n",
    "    top_graphemes = class_map_df[class_map_df['component_type'] == field].reset_index().iloc[top_grapheme_roots]\n",
    "    top_graphemes.drop(['component_type', 'label'], axis=1, inplace=True)\n",
    "    top_graphemes.loc[:, 'count'] = top_grapheme_counts\n",
    "    return top_graphemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top 10 grapheme roots\n",
    "top_10_roots = get_n(train_df, 'grapheme_root', 10)\n",
    "top_10_roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the bottom 5 grapheme roots\n",
    "bottom_10_roots = get_n(train_df, 'grapheme_root', 10, False)\n",
    "bottom_10_roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top 5 vowels\n",
    "top_5_vowels = get_n(train_df, 'vowel_diacritic', 5)\n",
    "top_5_vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top 5 consonants\n",
    "top_5_consonants = get_n(train_df, 'consonant_diacritic', 5)\n",
    "top_5_consonants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using PySpark to run machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression and random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape = (IMG_SIZE, IMG_SIZE, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge two tables - all the training parquet images to the training set \n",
    "for i in range(4):\n",
    "    train_df_ = pd.merge(pd.read_parquet(f'/Users/jihunlee/Desktop/bengali/train_image_data_{i}.parquet'), train_df, on='image_id').drop(['image_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unneeded columns\n",
    "X_train = train_df_.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'], axis=1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the images before running machine learning - later deep learning algorithms\n",
    "def resize(df, size=64, need_progress_bar=True):\n",
    "    resized = {}\n",
    "    resize_size=64\n",
    "    if need_progress_bar:\n",
    "        for i in tqdm(range(df.shape[0])):\n",
    "            image=df.loc[df.index[i]].values.reshape(137,236)\n",
    "            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "            idx = 0 \n",
    "            ls_xmin = []\n",
    "            ls_ymin = []\n",
    "            ls_xmax = []\n",
    "            ls_ymax = []\n",
    "            for cnt in contours:\n",
    "                idx += 1\n",
    "                x,y,w,h = cv2.boundingRect(cnt)\n",
    "                ls_xmin.append(x)\n",
    "                ls_ymin.append(y)\n",
    "                ls_xmax.append(x + w)\n",
    "                ls_ymax.append(y + h)\n",
    "            xmin = min(ls_xmin)\n",
    "            ymin = min(ls_ymin)\n",
    "            xmax = max(ls_xmax)\n",
    "            ymax = max(ls_ymax)\n",
    "\n",
    "            roi = image[ymin:ymax,xmin:xmax]\n",
    "            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n",
    "            resized[df.index[i]] = resized_roi.reshape(-1)\n",
    "    else:\n",
    "        for i in range(df.shape[0]):\n",
    "            #image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size),None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n",
    "            image=df.loc[df.index[i]].values.reshape(137,236)\n",
    "            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n",
    "\n",
    "            idx = 0 \n",
    "            ls_xmin = []\n",
    "            ls_ymin = []\n",
    "            ls_xmax = []\n",
    "            ls_ymax = []\n",
    "            for cnt in contours:\n",
    "                idx += 1\n",
    "                x,y,w,h = cv2.boundingRect(cnt)\n",
    "                ls_xmin.append(x)\n",
    "                ls_ymin.append(y)\n",
    "                ls_xmax.append(x + w)\n",
    "                ls_ymax.append(y + h)\n",
    "            xmin = min(ls_xmin)\n",
    "            ymin = min(ls_ymin)\n",
    "            xmax = max(ls_xmax)\n",
    "            ymax = max(ls_ymax)\n",
    "\n",
    "            roi = image[ymin:ymax,xmin:xmax]\n",
    "            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n",
    "            resized[df.index[i]] = resized_roi.reshape(-1)\n",
    "    resized = pd.DataFrame(resized).T\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape\n",
    "X_train = resize(X_train2)/255\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for simplicity, only output grapheme_root\n",
    "indexer1 = StringIndexer(inputCols=X_train.columns[-1], outputCol=\"grapheme_root\").setHandleInvalid(\"skip\")\n",
    "inputs = [indexer1.getOutputCol()]\n",
    "encoder = OneHotEncoderEstimator(inputCols=inputs,  \\\n",
    "                                 outputCols=[\"grapheme_root\"])\n",
    "\n",
    "#run it through a pipeline\n",
    "pipeline = Pipeline(stages=[indexer1, encoder])\n",
    "pipeline = pipeline.fit(X_train).transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gather feature vector and identify features\n",
    "assembler = VectorAssembler(inputCols = inputs,\n",
    "                            outputCol = 'grapheme_root')\n",
    "pipeline = assembler.transform(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Set parameters for Logistic Regression\n",
    "lgr = LogisticRegression(maxIter=10, featuresCol = 'features', labelCol='label')\n",
    "\n",
    "# Fit the model to the data.\n",
    "lgrm = lgr.fit(train_df)\n",
    "\n",
    "# Given a dataset, predict each point's label, and show the results.\n",
    "predictions = lgrm.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "#print evaluation metrics\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "print(evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"}))\n",
    "print(evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Set parameters for the Random Forest.\n",
    "rfc = RandomForestClassifier(maxDepth=5, numTrees=15, impurity=\"gini\", labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "# Fit the model to the data.\n",
    "rfcm = rfc.fit(train_df)\n",
    "\n",
    "# Given a dataset, predict each point's label, and show the results.\n",
    "predictions = rfcm.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = rfcm.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(evaluator.evaluate(predictions2, {evaluator.metricName: \"accuracy\"}))\n",
    "print(evaluator.evaluate(predictions2, {evaluator.metricName: \"f1\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Sci-kit Learn and Keras ^___^ to Train 1) James-40 2) a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MY 40 LAYER MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25 convolution layer with doubling filters\n",
    "# SAME padding\n",
    "# drop rate = 30%\n",
    "# batch normalization = 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1))(inputs)\n",
    "model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "\n",
    "model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=64, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "\n",
    "model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=128, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "\n",
    "model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "model = Conv2D(filters=256, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "model = BatchNormalization(momentum=0.15)(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "\n",
    "model = Flatten()(model)\n",
    "model = Dense(1024, activation = \"relu\")(model)\n",
    "model = Dropout(rate=0.3)(model)\n",
    "dense = Dense(512, activation = \"relu\")(model)\n",
    "\n",
    "head_root = Dense(168, activation = 'softmax')(dense)\n",
    "head_vowel = Dense(11, activation = 'softmax')(dense)\n",
    "head_consonant = Dense(7, activation = 'softmax')(dense)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideally I should use cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "x_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant = train_test_split(X_train, Y_train_root, Y_train_vowel, Y_train_consonant, test_size=0.08, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "print(X_train.shape)\n",
    "\n",
    "Y_train_root = pd.get_dummies(train_df_['grapheme_root']).values\n",
    "Y_train_vowel = pd.get_dummies(train_df_['vowel_diacritic']).values\n",
    "Y_train_consonant = pd.get_dummies(train_df_['consonant_diacritic']).values\n",
    "\n",
    "print(f'Training images: {X_train.shape}')\n",
    "print(f'Training labels root: {Y_train_root.shape}')\n",
    "print(f'Training labels vowel: {Y_train_vowel.shape}')\n",
    "print(f'Training labels consonants: {Y_train_consonant.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this data augmentation function doesn't quite work\n",
    "# ideally I should implement this before running deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "class ImageDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n",
    "\n",
    "    def flow(self,\n",
    "             x,\n",
    "             y=None,\n",
    "             batch_size=32,\n",
    "             shuffle=True,\n",
    "             sample_weight=None,\n",
    "             seed=None,\n",
    "             save_to_dir=None,\n",
    "             save_prefix='',\n",
    "             save_format='png',\n",
    "             subset=None):\n",
    "\n",
    "        targets = None\n",
    "        target_lengths = {}\n",
    "        ordered_outputs = []\n",
    "        for output, target in y.items():\n",
    "            if targets is None:\n",
    "                targets = target\n",
    "            else:\n",
    "                targets = np.concatenate((targets, target), axis=1)\n",
    "            target_lengths[output] = target.shape[1]\n",
    "            ordered_outputs.append(output)\n",
    "\n",
    "\n",
    "        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n",
    "                                         shuffle=shuffle):\n",
    "            target_dict = {}\n",
    "            i = 0\n",
    "            for output in ordered_outputs:\n",
    "                target_length = target_lengths[output]\n",
    "                target_dict[output] = flowy[:, i: i + target_length]\n",
    "                i += target_length\n",
    "\n",
    "            yield flowx, target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=8,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.15, # Randomly zoom image \n",
    "        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = []\n",
    "batch_size = 256\n",
    "epochs = 5 # only 5 epochs for computational ease\n",
    "\n",
    "\n",
    "histories = []\n",
    "history = model.fit_generator(datagen.flow(x_train, {'dense_3': y_train_root, 'dense_4': y_train_vowel, 'dense_5': y_train_consonant}, batch_size=batch_size),\n",
    "                              epochs = epochs, validation_data = (x_test, [y_test_root, y_test_vowel, y_test_consonant]), \n",
    "                              steps_per_epoch=x_train.shape[0] // batch_size )\n",
    " \n",
    "histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom make performance function per epochs\n",
    "%matplotlib inline\n",
    "def plot_loss(cls,epoch,title):\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0,epoch),cls.history['loss'],label = 'train_loss')\n",
    "    plt.plot(np.arange(0,epoch),cls.history['dense_3_loss'],label = 'train_root_loss')\n",
    "    plt.plot(np.arange(0,epoch),cls.history['dense_4_loss'],label = 'train_vowel_loss')\n",
    "    plt.plot(np.arange(0,epoch),cls.history['dense_5_loss'],label = 'train_consonant_loss')\n",
    "    plt.plot(np.arange(0,epoch),cls.history['val_dense_3_loss'],label = 'val_train_root_loss')\n",
    "    plt.plot(np.arange(0,epoch),cls.history['val_dense_4_loss'],label = 'val_train_vowel_loss')\n",
    "    plt.plot(np.arange(0,epoch),cls.history['val_dense_5_loss'],label = 'val_train_consonant_loss')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xlabel('Number of Epoch ')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_accuracy(cls,epoch,title):\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0,epoch),cls.history['dense_3_accuracy'],label = 'train_root_accuracy')\n",
    "    plt.plot(np.arange(0,epoch),cls.history['dense_4_accuracy'],label = 'train_vowel_accuracy')\n",
    "    plt.plot(np.arange(0,epoch),cls.history['dense_5_accuracy'],label = 'train_comnsonant_accuracy')\n",
    "    plt.plot(np.arange(0,epoch),cls.history['val_dense_3_accuracy'],label = 'val_train_root_accuracy')\n",
    "    plt.plot(np.arange(0,epoch),cls.history['val_dense_4_accuracy'],label = 'val_train_vowel_accuracy')\n",
    "    plt.plot(np.arange(0,epoch),cls.history['val_dense_5_accuracy'],label = 'val_train_consonant_accuracy')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Number of Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in range(1):\n",
    "    plot_loss(histories[dataset], epochs, f'Training Dataset: {dataset}')\n",
    "    plot_accuracy(histories[dataset], epochs, f'Training Dataset: {dataset}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this time use multi-classification\n",
    "pred_dict = {\n",
    "    'grapheme_root': [],\n",
    "    'vowel_diacritic': [],\n",
    "    'consonant_diacritic': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\n",
    "target=[] # model predictions placeholder\n",
    "row_id=[] # row_id place holder\n",
    "for i in range(4):\n",
    "    df_test_img = pd.read_parquet('/kaggle/input/bengaliai-cv19/test_image_data_{}.parquet'.format(i)) \n",
    "    df_test_img.set_index('image_id', inplace=True)\n",
    "\n",
    "    X_test = resize(df_test_img, need_progress_bar=False)/255\n",
    "    X_test = X_test.values.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    for i, p in enumerate(pred_dict):\n",
    "        pred_dict[p] = np.argmax(preds[i], axis=1)\n",
    "\n",
    "    for k,id in enumerate(df_test_img.index.values):  \n",
    "        for i,comp in enumerate(components):\n",
    "            id_sample=id+'_'+comp\n",
    "            row_id.append(id_sample)\n",
    "            target.append(pred_dict[comp][k])\n",
    "    del df_test_img\n",
    "    del X_test\n",
    "    gc.collect()\n",
    "\n",
    "df_sample = pd.DataFrame(\n",
    "    {\n",
    "        'row_id': row_id,\n",
    "        'target':target\n",
    "    },\n",
    "    columns = ['row_id','target'] \n",
    ")\n",
    "df_sample.to_csv('submission.csv',index=False)\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18,self).__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=2,stride=2,padding=3,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.MaxPool2d(1,1),\n",
    "            ResidualBlock(64,64),\n",
    "            ResidualBlock(64,64,2)\n",
    "        )\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            ResidualBlock(64,128),\n",
    "            ResidualBlock(128,128,2)\n",
    "        )\n",
    "        \n",
    "        self.block4 = nn.Sequential(\n",
    "            ResidualBlock(128,256),\n",
    "            ResidualBlock(256,256,2)\n",
    "        )\n",
    "        self.block5 = nn.Sequential(\n",
    "            ResidualBlock(256,512),\n",
    "            ResidualBlock(512,512,2)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(2)\n",
    "        # vowel_diacritic\n",
    "        self.fc1 = nn.Linear(512,11)\n",
    "        # grapheme_root\n",
    "        self.fc2 = nn.Linear(512,168)\n",
    "        # consonant_diacritic\n",
    "        self.fc3 = nn.Linear(512,7)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc2(x)\n",
    "        x3 = self.fc3(x)\n",
    "        return x1,x2,x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def __init__(self):\n",
    "        super(ResNet34,self).__init__()\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=2,stride=2,padding=3,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.MaxPool2d(1,1),\n",
    "            ResidualBlock(64,64),\n",
    "            ResidualBlock(64,64,2)\n",
    "        )\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            ResidualBlock(64,128),\n",
    "            ResidualBlock(128,128,2)\n",
    "        )\n",
    "        \n",
    "        self.block4 = nn.Sequential(\n",
    "            ResidualBlock(128,256),\n",
    "            ResidualBlock(256,256,2)\n",
    "        )\n",
    "        self.block5 = nn.Sequential(\n",
    "            ResidualBlock(256,512),\n",
    "            ResidualBlock(512,512,2)\n",
    "        )\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(2)\n",
    "        # vowel_diacritic\n",
    "        self.fc1 = nn.Linear(512,11)\n",
    "        # grapheme_root\n",
    "        self.fc2 = nn.Linear(512,168)\n",
    "        # consonant_diacritic\n",
    "        self.fc3 = nn.Linear(512,7)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x1 = self.fc1(x)\n",
    "        x2 = self.fc2(x)\n",
    "        x3 = self.fc3(x)\n",
    "        return x1,x2,x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet34().to(device)\n",
    "optimizer = optimizer = torch.optim.Adam(model.parameters(), lr=4e-4)\n",
    "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-4, max_lr=0.05)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "model.train()\n",
    "losses = []\n",
    "accs = []\n",
    "for epoch in range(epochs):\n",
    "    reduced_index =train.groupby(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']).apply(lambda x: x.sample(5)).image_id.values\n",
    "    reduced_train = train.loc[train.image_id.isin(reduced_index)]\n",
    "    reduced_data = data_full.loc[data_full.image_id.isin(reduced_index)]\n",
    "    train_image = GraphemeDataset(reduced_data,reduced_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_image,batch_size=batch_size,shuffle=True)\n",
    "    \n",
    "    print('epochs {}/{} '.format(epoch+1,epochs))\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    for idx, (inputs,labels1,labels2,labels3) in tqdm(enumerate(train_loader),total=len(train_loader)):\n",
    "        inputs = inputs.to(device)\n",
    "        labels1 = labels1.to(device)\n",
    "        labels2 = labels2.to(device)\n",
    "        labels3 = labels3.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs1,outputs2,outputs3 = model(inputs.unsqueeze(1).float())\n",
    "        loss1 = criterion(outputs1,labels1)\n",
    "        loss2 = criterion(outputs2,labels2)\n",
    "        loss3 = criterion(outputs3,labels3)\n",
    "        running_loss += loss1+loss2+loss3\n",
    "        running_acc += (outputs1.argmax(1)==labels1).float().mean()\n",
    "        running_acc += (outputs2.argmax(1)==labels2).float().mean()\n",
    "        running_acc += (outputs3.argmax(1)==labels3).float().mean()\n",
    "        (loss1+loss2+loss3).backward()\n",
    "        optimizer.step()\n",
    "    #scheduler.step()\n",
    "    losses.append(running_loss/len(train_loader))\n",
    "    accs.append(running_acc/(len(train_loader)*3))\n",
    "    print('acc : {:.2f}%'.format(running_acc/(len(train_loader)*3)))\n",
    "    print('loss : {:.4f}'.format(running_loss/len(train_loader)))\n",
    "torch.save(model.state_dict(), 'resnet34_50epochs_saved_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot \n",
    "fig,ax = plt.subplots(1,2,figsize=(15,5))\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_title('loss')\n",
    "ax[1].plot(accs)\n",
    "ax[1].set_title('acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... now finally efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 137\n",
    "WIDTH = 236\n",
    "FACTOR = 0.70\n",
    "HEIGHT_NEW = int(HEIGHT * FACTOR)\n",
    "WIDTH_NEW = int(WIDTH * FACTOR)\n",
    "CHANNELS = 3\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Prep for EfficientNet\n",
    "def resize_image(img, WIDTH_NEW, HEIGHT_NEW):\n",
    "    # Invert\n",
    "    img = 255 - img\n",
    "\n",
    "    # Normalize\n",
    "    img = (img * (255.0 / img.max())).astype(np.uint8)\n",
    "\n",
    "    # Reshape\n",
    "    img = img.reshape(HEIGHT, WIDTH)\n",
    "    image_resized = cv2.resize(img, (WIDTH_NEW, HEIGHT_NEW), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    return image_resized.reshape(-1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized mean pool - GeM\n",
    "gm_exp = tf.Variable(3.0, dtype = tf.float32)\n",
    "def generalized_mean_pool_2d(X):\n",
    "    pool = (tf.reduce_mean(tf.abs(X**(gm_exp)), \n",
    "                        axis = [1, 2], \n",
    "                        keepdims = False) + 1.e-7)**(1./gm_exp)\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "def create_model(input_shape):\n",
    "    # Input Layer\n",
    "    input = Input(shape = input_shape)\n",
    "    \n",
    "    # Create and Compile Model and show Summary\n",
    "    x_model = efn.EfficientNetB3(weights = None, include_top = False, input_tensor = input, pooling = None, classes = None)\n",
    "    \n",
    "    # UnFreeze all layers\n",
    "    for layer in x_model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    # GeM\n",
    "    lambda_layer = Lambda(generalized_mean_pool_2d)\n",
    "    lambda_layer.trainable_weights.extend([gm_exp])\n",
    "    x = lambda_layer(x_model.output)\n",
    "    \n",
    "    # multi output\n",
    "    grapheme_root = Dense(168, activation = 'softmax', name = 'root')(x)\n",
    "    vowel_diacritic = Dense(11, activation = 'softmax', name = 'vowel')(x)\n",
    "    consonant_diacritic = Dense(7, activation = 'softmax', name = 'consonant')(x)\n",
    "\n",
    "    # model\n",
    "    model = Model(inputs = x_model.input, outputs = [grapheme_root, vowel_diacritic, consonant_diacritic])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "model1 = create_model(input_shape = (HEIGHT_NEW, WIDTH_NEW, CHANNELS))\n",
    "model2 = create_model(input_shape = (HEIGHT_NEW, WIDTH_NEW, CHANNELS))\n",
    "model3 = create_model(input_shape = (HEIGHT_NEW, WIDTH_NEW, CHANNELS))\n",
    "model4 = create_model(input_shape = (HEIGHT_NEW, WIDTH_NEW, CHANNELS))\n",
    "model5 = create_model(input_shape = (HEIGHT_NEW, WIDTH_NEW, CHANNELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model Weights : these are pretrained model weights that save us a lot of time\n",
    "model1.load_weights('../input/kerasefficientnetb3/Train1_model_59.h5') \n",
    "model2.load_weights('../input/kerasefficientnetb3/Train1_model_64.h5') \n",
    "model3.load_weights('../input/kerasefficientnetb3/Train1_model_68.h5') \n",
    "model4.load_weights('../input/kerasefficientnetb3/Train1_model_57.h5') \n",
    "model5.load_weights('../input/kerasefficientnetb3/Train1_model_70.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_cols = ['grapheme_root','vowel_diacritic','consonant_diacritic']\n",
    "\n",
    "# Create Predictions\n",
    "row_ids, targets = [], []\n",
    "\n",
    "# Loop through Test Parquet files (X)\n",
    "for i in range(0, 4):\n",
    "    # Test Files Placeholder\n",
    "    test_files = []\n",
    "\n",
    "    # Read Parquet file\n",
    "    df = pd.read_parquet(os.path.join(DIR, 'test_image_data_'+str(i)+'.parquet'))\n",
    "    # Get Image Id values\n",
    "    image_ids = df['image_id'].values \n",
    "    # Drop Image_id column\n",
    "    df = df.drop(['image_id'], axis = 1)\n",
    "\n",
    "    # Loop over rows in Dataframe and generate images \n",
    "    X = []\n",
    "    for image_id, index in zip(image_ids, range(df.shape[0])):\n",
    "        test_files.append(image_id)\n",
    "        X.append(resize_image(df.loc[df.index[index]].values, WIDTH_NEW, HEIGHT_NEW))\n",
    "\n",
    "    # Data_Generator\n",
    "    data_generator_test = TestDataGenerator(X, batch_size = BATCH_SIZE, img_size = (HEIGHT_NEW, WIDTH_NEW, CHANNELS))\n",
    "        \n",
    "    # Predict with all 3 models\n",
    "    preds1 = model1.predict_generator(data_generator_test, verbose = 1)\n",
    "    preds2 = model2.predict_generator(data_generator_test, verbose = 1)\n",
    "    preds3 = model3.predict_generator(data_generator_test, verbose = 1)\n",
    "    preds4 = model4.predict_generator(data_generator_test, verbose = 1)\n",
    "    preds5 = model5.predict_generator(data_generator_test, verbose = 1)\n",
    "    \n",
    "    # Loop over Preds    \n",
    "    for i, image_id in zip(range(len(test_files)), test_files):\n",
    "        \n",
    "        for subi, col in zip(range(len(preds1)), tgt_cols):\n",
    "            sub_preds1 = preds1[subi]\n",
    "            sub_preds2 = preds2[subi]\n",
    "            sub_preds3 = preds3[subi]\n",
    "            sub_preds4 = preds4[subi]\n",
    "            sub_preds5 = preds5[subi]\n",
    "\n",
    "            # Set Prediction with average of 5 predictions\n",
    "            row_ids.append(str(image_id)+'_'+col)\n",
    "            sub_pred_value = np.argmax((sub_preds1[i] + sub_preds2[i] + sub_preds3[i] + sub_preds4[i] + sub_preds5[i]) / 5)\n",
    "            targets.append(sub_pred_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
